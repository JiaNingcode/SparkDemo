import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

/**
 * RDD : 弹性分布式数据集
 *   1. RDD 可以看作是一些列partition组成的
 *   2. RDD 之间存在依赖关系
 *   3. 算子是作用在partition上的
 *   4. 分区器是作用在kv形式的RDD上的
 *   5. partition 提供最佳计算位置，即计算像数据移动
 *
 * RDD 的弹性
 *   1. 自动进行内存和磁盘数据存储切换（优先将数据放到内存中，内存不够放入磁盘）
 *   2. 基于血缘的高容错机制 （RDD进行转化和行动算子，会形成rdd之间的依赖链，当某个rdd失效可以通过冲击计算上游rdd重新生成丢失rdd数据）
 *   3. Task、stage 失败会重新计算（默认4次）
 *   4. checkpoint（检查点机制）和persist（持久化） 可以主动或被动触发
 *   5. 数据分片高度弹性。可以根据业务特征，动态调整数据分片个数
 */
object SparkDemo2 extends App {

}

class CreateRdd {
  /**
   * 创建RDD两种方式：
   *   1.从集合中创建
   *   2.从外部存储创建
   */
  // 1.从集合中创建
  val conf = new SparkConf().setAppName("Test").setMaster("local")
  val context = new SparkContext(conf)
  // makeRDD底层实现是parallelize,这两种方法第二个参数默认值是2 ，表示分片（partition的数量）
  context.makeRDD(Array(1,2,3,4,5),2)
  context.parallelize(Array(1,2,3,4,5),2)

  // 2.从外部存储创建rdd
  context.textFile("xxx")
}

/**
 * Transformation算子
 *   Value型Transformation算子,针对处理的数据项是Value型的数据。
 *   Key-Value数据类型的Transformation算子，针对处理的数据项是Key-Value型的数据。
 */
class Transformation {
  val sc = new CreateRdd().context

  // 1 map(func) => 返回一个新的RDD，该RDD由每一个输入元素经过func函数转换后组成
  val map1: RDD[String] = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3)
  val map2: RDD[Int] = map1.map(_.length) // RDD[3,6,6,3,8]
  val map3: RDD[(String, Int)] = map1.zip(map2) //zip方法主要用于将两个RDD中的元素按照对应位置进行组合，形成一个新的RDD（zip操作要求两个RDD具有相同的长度。如果长度不同，较短的那个RDD会决定结果RDD的长度）
  map3.collect() // 调用行动操作 `collect()来触发计算并获取结果  Array((dog,3), (salmon,6), (salmon,6), (rat,3), (elephant,8))

  /*
     mapPartitions是map的一个变种。map的输入函数应用于RDD中的每个元素，而mapPartitions的输入函数应用于每个分区，也就是把每个分区中的内容作为整体来处理的。
   */
  // 2 mapPartitions(func) => 类似于map，但独立地在RDD的每一个分片上运行，因此在类型为T的RDD上运行时，func的函数类型必须是Iterator[T] => Iterator[U]
  val mapPart1: RDD[String] = sc.parallelize(List("dog", "cat", "chick", "monkey"))
  val mapPart2: RDD[String] = mapPart1.mapPartitions(iterator => iterator.filter(_.length > 3)) //filter(func) 返回一个新的RDD，该RDD由经过func函数计算后返回值为true的输入元素组成
  mapPart2.collect() //Array(chick, monkey)

  // 3 mapPartitionsWithIndex(func) => 类似于mapPartitions，但func带有一个整数参数表示分片的索引值，因此在类型为T的RDD上运行时，func的函数类型必须是(Int, Iterator[T]) => Iterator[U]
  val mapPartWithIndex1 = sc.parallelize(List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 3) // 一共3个分区

  def func(index: Int, iterator: Iterator[Int]): Iterator[String] = {
    iterator.map(x => index + ":" + x) //index 整数参数表示分片的索引值
  }

  mapPartWithIndex1.mapPartitionsWithIndex(func).collect() // Array(0:1, 0:2, 0:3, 1:4, 1:5, 1:6, 2:7, 2:8, 2:9, 2:10)  分区索引为0，1，2

  // 4 glom() => 将每一个分区形成一个数组，形成新的RDD类型时RDD[Array[T]]
  sc.parallelize(1 to 20, 4).collect() //glom() 方法会将每个分区中的元素转换为一个数组 Array(Array(1, 2, 3, 4), Array(5, 6, 7, 8), Array(9, 10, 11, 12), Array(13, 14, 15, 16, 17, 18, 19, 20))

  // 5 flatMap(func) => 	类似于map(先map映射 再flat扁平化)，但是每一个输入元素可以被映射为0或多个输出元素（所以func应该返回一个序列，而不是单一元素）
  sc.parallelize(Array(1, 2, 3), 2).flatMap(x => Array(x, x)).collect() //Array(1,1,2,2,3,3)

  // 6 union => 将两个RDD中的数据集进行合并，最终返回两个RDD的并集，若RDD中存在相同的元素也不会去重
  val union1 = sc.parallelize(1 to 3, 1)
  val union2 = sc.parallelize(5 to 7, 1)
  union1.union(union2).collect() // Array(1, 2, 3, 1, 2, 3, 4, 5, 6, 7)

  // 7 groupBy =>分组，按照传入函数的返回值进行分组。将相同的key对应的值放入一个迭代器。
  val groupBy1 = sc.parallelize(1 to 9, 3)
  groupBy1.groupBy(_ % 2).collect() //Array((0,CompactBuffer(2, 4, 6, 8)), (1,CompactBuffer(1, 3, 5, 7, 9)))

  // 8 filter => 对元素进行过滤，对每个元素应用f函数，返回值为true的元素在RDD中保留，返回为false的将过滤掉
  sc.parallelize(1 to 10, 3).filter(_ % 2 == 0).collect() //  Array(2, 4, 6, 8, 10)

  // 9 distinct([numTasks]))
  sc.parallelize(List("Gnu", "Cat", "Rat", "Dog", "Gnu", "Rat"), 2).distinct().collect() //Array(Dog, Gnu, Cat, Rat)

  // 10 sample(withReplacement, fraction, seed) => 以指定的随机种子随机抽样出数量为fraction的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样,seed用于指定随机数生成器种子
  sc.parallelize(1 to 10000, 3).sample(false, 0.1, 0).count() //- `0.1` 是抽样的比例，意味着大约抽取10%的数据。 - `0` 是随机种子，是一个用来初始化随机数生成器的初始值

  // cache、persist => cache和persist都是用于将一个RDD进行缓存的，这样在之后使用的过程中就不需要重新计算了，可以大大节省程序运行时间。
  sc.parallelize(List("Gnu", "Cat", "Rat", "Dog", "Gnu", "Rat"), 2).cache()

  // 11 mapValues => mapValues是针对[K,V]中的V值进行map操作
  val mapVal: RDD[String] = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther", "eagle"), 2)
  mapVal.map(x=>(x.length,x)).mapValues("x" + _ + "x").collect //Array((3,xdogx), (5,xtigerx), (4,xlionx), (3,xcatx), (7,xpantherx), (5,xeaglex))

  /*
     12 combineByKey[C](createCombiner: V => C,mergeValue: (C, V) => C,mergeCombiners: (C, C) => C) =>
                    用用户设置好的聚合函数对每个Key中的Value进行组合(combine)。可以将输入类型为RDD[(K, V)]转成成RDD[(K, C)] 对相同Key，把Value合并成一个集合.
           createCombiner(初始化组合器): combineByKey() 会遍历分区中的所有元素，因此每个元素的键要么还没有遇到过，要么就和之前的某个元素的键相同。如果这是一个新的元素,combineByKey()
                           会使用一个叫作 createCombiner() 的函数来创建那个键对应的累加器的初始值

           mergeValue（将新值合并到组合器中）: 如果这是一个在处理当前分区之前已经遇到的键， 它会使用 mergeValue() 方法将该键的累加器对应的当前值与这个新的值进行合并

           mergeCombiners（合并不同分区组合器）: 由于每个分区都是独立处理的， 因此对于同一个键可以有多个累加器。 如果有两个或者更多的分区都有对应同一个键的累加器，
                           就需要使用用户提供的 mergeCombiners() 方法将各个分区的结果进行合并。
   */
  val score = sc.parallelize(Seq(("maths", 50), ("maths", 60), ("english", 65), ("physics", 66), ("physics", 61), ("physics", 87)), 2)
  val reduce = score.combineByKey(
    // ("maths", 50) 组合器 (50,1)
    score => (score, 1),
    // 第一次("physics", 66) 组合为(66,1) 第二次 ("physics", 61) 组合为 (66+61,1+1)
    (acc: (Int, Int), score:Int) => (acc._1 + score, acc._2 + 1),
    // 分区2中 ("physics", (66,1)) 分区3中 ("physics",(61+87,1+1)) 合并结果为 ("physics", (66+61+87,1+1+1))
    (acc1: (Int, Int), acc2: (Int, Int)) => (acc1._1 + acc2._1, acc1._2 + acc2._2)
  )
  reduce.collect() // Array((maths,(110,2)), (physics,(214,3)), (english,(65,1)))
  //计算各科成绩平均值
  val result = reduce.mapValues(x=>x._1 / x._2)
  result.collect() //Array((maths,55.0), (physics,71.333336), (english,65.0))

  // 13 reduceByKey =>  对元素为KV对的RDD中Key相同的元素的Value进行reduce操作
  val reduce1 = sc.parallelize(List("dog", "tiger", "lion", "cat", "panther", "eagle"), 2)
  val reduce2 = reduce1.map(x => (x.length, x))
  reduce2.reduceByKey(_ + _).collect  //Array((4,lion), (3,dogcat), (7,panther), (5,tigereagle))

  /*
     14 aggregateByKey(zeroValue)(seqOp, combOp, [numTasks]) =>
            在kv对的RDD中，按key将value进行分组合并，合并时，将每个value和初始值作为seqOp函数的参数进行计算，返回的结果作为一个新的kv对，然后再将结果按照key进行合并，
            最后将每个分组的value传递给combOp函数进行计算（先将前两个value进行计算，将返回结果和下一个value传给comb函数，以此类推），将key与计算结果作为一个新的kv对输出。
            seqOp函数用于在每一个分区中用初始值逐步迭代value，combOp函数用于合并每个分区中的结果
            zeroValue是初始值(默认值) seqOP局部聚合(分区)  combOp 全局聚合
  */
  val pairRDD = sc.parallelize(List( ("cat",2), ("cat", 5), ("mouse", 4),("cat", 12), ("dog", 12), ("mouse", 2)), 2)
  pairRDD.aggregateByKey(0)(math.max(_, _), _ + _).collect  //Array((dog,12), (cat,17), (mouse,6))
  pairRDD.aggregateByKey(100)(math.max(_, _), _ + _).collect //Array((dog,100), (cat,200), (mouse,200))

  // 15 groupByKey([numTasks]) => 在一个(K,V)的RDD上调用，返回一个(K, Iterator[V])的RDD  每次结果可能不同，因为发生shuffle
  val wordPairsRDD = reduce1.keyBy(_.length)
  val wordCountsWithGroup = wordPairsRDD .groupByKey().collect // Array((4,CompactBuffer(lion)), (6,CompactBuffer(spider)), (3,CompactBuffer(dog, cat)), (5,CompactBuffer(tiger, eagle)))

  // 16 keyBy => 通过在每个元素上应用一个函数生成键值对中的键，最后构成一个键值对元组。
  sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3).keyBy(_.length).collect() //Array((3,dog), (6,salmon), (6,salmon), (3,rat), (8,elephant))

  // 17 sortByKey([ascending], [numTasks]) => 根据key进行排序,但是key必须实现Ordered接口 可根据传入的true 或 false 决定是升序 还是 降序 参数默认是true
  val rdd_sortByKey = sc.parallelize(Array((3,"aa"),(6,"cc"),(2,"bb"),(1,"dd")))
  val sorted: RDD[(Int, String)] = rdd_sortByKey.sortByKey(true)
  sorted.collect().toList // List((1,"dd"), (2,"bb"), (3,"aa"), (6,"cc"))

  // 18 sortBy(func,[ascending], [numTasks]) => 与sortByKey类似,但是更灵活,可以用func先对数据进行处理, 然后按处理后的数据比较结果排序 第一个参数:是处理数据的方式 第二个参数:是排序方式 默认是true 升序
  val rdd_sortBy = sc.parallelize(List(5,6,4,7,3,8,2,9,10))
  val sorted2: RDD[Int] = rdd_sortBy.sortBy(x => x, true)
  sorted2.collect() // Array(2, 3, 4, 5, 6, 7, 8, 9, 10)

  // 19 repartition =>  更改分区repartition可以从少量分区改变为多分区因为会发生shuffle
  sc.parallelize(List(1,2,3,4,5,6),3).repartition(5)

  // 20 coalesce(numPartitions**) => 更改分区 不可以少量分区更改为多分区,因为不会发生shuffle 缩减分区数，用于大数据集过滤后，提高小数据集的执行效率。

  // 21 cogroup => 对两个RDD中的KV元素,每个RDD中相同key中的元素分别聚合成一个集合。
  val a = sc.parallelize(List(1, 2, 1, 3), 1)
  val b = a.map((_, "b"))
  val c = a.map((_, "c"))
  b.cogroup(c).collect //Array((2,(ArrayBuffer(b),ArrayBuffer©)),(3,(ArrayBuffer(b),ArrayBuffer©)),(1,(ArrayBuffer(b, b),ArrayBuffer(c, c))))

  // 21 join => 对两个需要连接的RDD进行cogroup函数操作 / leftOutJoin / rightOutJoin
  val tbl1 = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3).keyBy(_.length)
  val tbl2 = sc.parallelize(List("dog","cat","gnu","salmon","rabbit","turkey","wolf","bear","bee"), 3).keyBy(_.length)

  tbl1.join(tbl2).collect()  // Array((6,(salmon,salmon)), (6,(salmon,rabbit)), (6,(salmon,turkey)), (6,(salmon,salmon)), (6,(salmon,rabbit)), (6,(salmon,turkey)), (3,(dog,dog)), (3,(dog,cat)), (3,(dog,gnu)), (3,(dog,bee)), (3,(rat,dog)), (3,(rat,cat)), (3,(rat,gnu)), (3,(rat,bee)))
}

/**
 * Actions算子
 *   这类算子会触发SparkContext提交作业。
 */
class Actions {
  val sc = new CreateRdd().context

  // 1 foreach 打印输出
  val foreach1 = sc.parallelize(List("cat", "dog", "tiger", "lion", "gnu", "crocodile", "ant", "whale", "dolphin", "spider"), 3)
  foreach1.foreach(println)

  // 2 saveAsTextFile => 将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统
  sc.parallelize(1 to 10000, 3).saveAsTextFile("xxx")

  // 3 saveAsObjectFile => saveAsObjectFile用于将RDD中的元素序列化成对象，存储到文件中。对于HDFS，默认采用SequenceFile保存。
  sc.parallelize(1 to 100, 3).saveAsObjectFile("/user/yuhui/objFile")

  // 4 collect => 将RDD中的数据收集起来，变成一个Array，仅限数据量比较小的时候。

  // 5 count => 返回RDD的元素个数
  sc.parallelize(List("Gnu", "Cat", "Rat", "Dog"), 2).count // 4

  // 6 top => 返回最大的K个元素 ; takeOrdered(n, [ordering]) => takeOrdered和top类似，只不过以和top相反的顺序返回元素
  sc.parallelize(Array(6, 9, 4, 7, 5, 8), 2).top(2) // Array(9, 8)

  // 7 first() => 返回RDD的第一个元素（类似于take(1)）

  // 8 take(n) => 返回一个由数据集的前n个元素组成的数组

  // 9 fold => fold()与reduce()类似，接收与reduce接收的函数签名相同的函数，另外再加上一个初始值作为第一次调用的结果。
  sc.parallelize(List(1,2,3), 3).fold(0)(_ + _) // 0+1+2+3=6

  // 9 aggregate => aggregate先对每个分区的所有元素进行aggregate操作，再对分区的结果执行fold操作。
  val agg = sc.parallelize(List(1,2,3,4,5,6), 2)
  agg.aggregate(0)(math.max(_, _), _ + _)  // `math.max(_, _)` 函数会在每个分区中找到最大值。因此，在第一个分区 `[1,2,3]` 中，最大值是 `3`；在第二个分区 `[4,5,6]` 中，最大值是 `6`。然后，`_ + _` 函数会将这两个分区的最大值相加，即 `3 + 6 = 9`。
}

/**
 * 算子比较
 * 1.map \ flatMap\ mapPartitions \ mapPartitionsWithIndex  (Spark中，最基本的原则，就是每个task处理一个RDD的partition。)
 *     1.1. **map**
 *        - `map(func)` 对RDD中的每个元素应用一个函数 `func`，并返回一个新的RDD。
 *        - 每个元素独立地被处理，不会影响到其他元素。
 *        - 示例：将字符串RDD中的每个单词转换为大写。
 *
 *     1.2. **flatMap**
 *        - `flatMap(func)` 类似于 `map`，但它允许你从每个输入元素生成0个或多个输出元素。
 *        - 这种方式可以用来扁平化数据结构，例如将列表中的每个元素拆分成多个元素。
 *        - 示例：将包含多个单词的字符串列表转换成单个单词的列表。
 *
 *     1.3. **mapPartitions**
 *        - `mapPartitions(func)` 对RDD中的每个分区应用一个函数 `func`，而不是对每个元素。
 *        - 这意味着对于每个分区，函数 `func` 只会被调用一次，并且它会接收该分区的所有元素作为迭代器。
 *        - 这种方法可以减少函数调用的开销，特别是在函数内部有初始化操作时。
 *        - 示例：如果需要对每个分区的数据进行预处理（如排序），可以使用 `mapPartitions`。
 *
 *     1.4. **mapPartitionsWithIndex**
 *        - `mapPartitionsWithIndex(func)` 类似于 `mapPartitions`，但是它还提供了一个参数，即分区的索引。
 *        - 这使得你可以根据分区的索引来执行不同的操作。
 *        - 示例：如果你需要根据分区的索引来决定是否处理某个分区的数据，或者根据分区的索引来进行一些特定的操作，可以使用 `mapPartitionsWithIndex`。
 *
 *     总结:
 *       `map` 和 `flatMap` 更适合于简单的元素级转换
 *       `mapPartitions` 和 `mapPartitionsWithIndex` 则更适合于需要对整个分区进行操作的情况，这样可以减少函数调用的次数，从而提高效率。
 *
 *
 * 2. reduceByKey \ groupByKey \ aggregateByKey \ combineByKey
 *     2.1. **reduceByKey**:
 *        - 功能：它将具有相同键的所有值合并在一起，并使用一个函数来减少这些值。
 *        - 使用场景：当你需要对每个键的值进行某种形式的聚合操作时，比如求和、计数等。
 *        - 性能：在 shuffle 之前会在每个分区内进行局部聚合，减少数据传输量。
 *
 *     2.2. **groupByKey**:
 *        - 功能：它将具有相同键的所有值收集到一起，形成一个新的键值对，其中键是原始键，而值是一个包含所有对应值的迭代器。
 *        - 使用场景：当你需要对每个键的所有值进行进一步处理，但不需要立即应用一个聚合函数时。
 *        - 性能：没有局部聚合，所有数据都会在 shuffle 阶段传输，可能会导致较大的数据传输量。
 *
 *     2.3. **aggregateByKey**:
 *        - 功能：它允许你定义两个阶段的聚合操作：首先是在每个分区内部进行局部聚合（通过一个给定的零值和一个局部聚合函数），然后是全局聚合（通过另一个函数）。
 *        - 使用场景：当你需要进行复杂的聚合操作，可能涉及到多个步骤或状态维护时。
 *        - 性能：在 shuffle 之前会在每个分区内进行局部聚合，减少数据传输量。
 *
 *     2.4. **combineByKey**:
 *        - 功能：它允许你定义如何创建初始值、如何组合局部结果以及如何合并不同分区的结果。这个方法提供了最大的灵活性，可以用来实现非常复杂的聚合逻辑。
 *        - 使用场景：当你需要自定义聚合过程中的每一个步骤时，比如初始化、局部聚合和最终聚合。
 *        - 性能：在 shuffle 之前会在每个分区内进行局部聚合，减少数据传输量。
 *
 *      总结：
 *        `reduceByKey`：适用于简单的聚合操作，性能较好。
 *        `groupByKey`：适用于需要将所有相同键的值分组的情况，但性能较差。
 *        `aggregateByKey`：适用于需要自定义初始值和聚合函数的场景，性能较好。
 *        `combineByKey`：适用于需要更灵活的自定义聚合操作的场景，性能较好。
 *
 *
 * 3. coalesce \ repartition
 *   (1) 都是用来重新分区的 repartition等价于 coalesce(numPartitions, shuffle = true).
 *   (2) coalesce 用来缩小分区，不会触发shuffle
 *   (3) repartition 用来扩大分区，会触发shuffle
 */
